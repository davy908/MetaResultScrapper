"""
Meta Ads Library Scraper - Web App
Vers√£o REFATORADA com estrutura correta da p√°gina do Facebook
"""

import streamlit as st
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import json
from datetime import datetime
import re

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Meta Ads Library Scraper",
    page_icon="üï∑Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        padding: 1rem 0;
    }
    .subtitle {
        text-align: center;
        color: #666;
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.75rem;
        font-size: 1.1rem;
        font-weight: bold;
        border-radius: 8px;
    }
    </style>
""", unsafe_allow_html=True)


@st.cache_resource
def get_driver():
    """
    Inicializa o ChromeDriver com configura√ß√µes otimizadas
    """
    options = Options()
    
    # Configura√ß√µes essenciais
    options.add_argument('--headless=new')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--disable-software-rasterizer')
    options.add_argument('--disable-extensions')
    options.add_argument('--disable-logging')
    options.add_argument('--log-level=3')
    options.add_argument('--silent')
    options.add_argument('--disable-blink-features=AutomationControlled')
    
    # User agent realista
    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    
    # Configura√ß√£o de janela
    options.add_argument('--window-size=1920,1080')
    
    # Usar Chromium do sistema
    options.binary_location = '/usr/bin/chromium'
    
    try:
        service = Service(executable_path='/usr/bin/chromedriver')
        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(60)
        return driver
    except Exception as e:
        st.error(f"‚ùå Erro ao iniciar Chrome: {str(e)}")
        return None


class MetaAdsScraper:
    """
    Scraper refatorado com estrutura correta do Facebook Ads Library
    """
    
    def __init__(self, driver):
        self.driver = driver
        self.wait = WebDriverWait(self.driver, 20) if driver else None
    
    def buscar_por_page_id(self, page_id):
        """Busca an√∫ncios de uma p√°gina espec√≠fica"""
        if not self.driver:
            return None
        
        url = f"https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=ALL&view_all_page_id={page_id}"
        
        try:
            self.driver.get(url)
            
            # Aguarda a p√°gina carregar completamente
            time.sleep(10)
            
            return self._extrair_dados()
        
        except Exception as e:
            return {
                'erro': str(e),
                'url': url,
                'timestamp': datetime.now().isoformat()
            }
    
    def buscar_por_url(self, url):
        """Busca por URL completa"""
        if not self.driver:
            return None
        
        # Extrai Page ID da URL
        match = re.search(r'view_all_page_id=(\d+)', url)
        if match:
            return self.buscar_por_page_id(match.group(1))
        
        # Ou usa a URL diretamente
        try:
            self.driver.get(url)
            time.sleep(10)
            return self._extrair_dados()
        except Exception as e:
            return {
                'erro': str(e),
                'url': url,
                'timestamp': datetime.now().isoformat()
            }
    
    def _extrair_dados(self):
        """
        Extrai dados da p√°gina do Facebook Ads Library
        Baseado na estrutura real da p√°gina
        """
        dados = {
            'timestamp': datetime.now().isoformat(),
            'url': self.driver.current_url,
            'total_resultados': None,
            'anuncios': []
        }
        
        # 1. Extrair contagem total de resultados
        # A contagem geralmente est√° em um heading com texto tipo "123 results"
        dados['total_resultados'] = self._extrair_total_resultados()
        
        # 2. Scroll para carregar os an√∫ncios
        self._scroll_progressivo(scrolls=5)
        
        # 3. Extrair cards de an√∫ncios
        dados['anuncios'] = self._extrair_anuncios()
        
        return dados
    
    def _extrair_total_resultados(self):
        """
        Extrai o n√∫mero total de resultados
        Exemplo: "34 results" ou "34 resultados"
        """
        try:
            # Tenta encontrar o elemento com a contagem
            # Baseado na sua observa√ß√£o: classe espec√≠fica com aria-level="3"
            selectors = [
                "div.x8t9es0.x1uxerd5.xrohxju.x108nfp6.xq9mrsl.x1h4wwuj.x117nqv4.xeuugli",
                "div[role='heading'][aria-level='3']",
                "h3",
                "[class*='result']"
            ]
            
            for selector in selectors:
                try:
                    elementos = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elementos:
                        texto = elem.text.strip()
                        # Procura por texto que contenha n√∫meros + "result" ou similar
                        if re.search(r'\d+\s*(result|an√∫nc|ad)', texto, re.IGNORECASE):
                            return texto
                except:
                    continue
            
            # Se n√£o encontrou, procura por qualquer texto com "result"
            try:
                elementos = self.driver.find_elements(By.XPATH, "//*[contains(text(), 'result') or contains(text(), 'an√∫nc')]")
                for elem in elementos[:5]:
                    texto = elem.text.strip()
                    if any(char.isdigit() for char in texto):
                        return texto
            except:
                pass
            
            return "N√£o encontrado"
        
        except Exception as e:
            return f"Erro: {str(e)}"
    
    def _extrair_anuncios(self):
        """
        Extrai cards de an√∫ncios individuais
        Cada an√∫ncio no Facebook Ads Library tem uma estrutura espec√≠fica
        """
        anuncios = []
        
        try:
            # O Facebook usa estruturas din√¢micas
            # Vamos procurar por padr√µes comuns de cards de an√∫ncios
            
            # Estrat√©gia 1: Procurar por links de snapshot de an√∫ncios
            # Cada an√∫ncio tem um link √∫nico para ver detalhes
            ad_links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='ad_library_id']")
            
            if ad_links:
                st.info(f"Encontrados {len(ad_links)} links de an√∫ncios")
                
                # Para cada link, pega o container pai que deve ter o conte√∫do do an√∫ncio
                for idx, link in enumerate(ad_links[:30]):  # Limita a 30
                    try:
                        # Pega o container do an√∫ncio (geralmente v√°rios n√≠veis acima)
                        ad_container = link.find_element(By.XPATH, "./ancestor::div[contains(@class, 'x1y1aw1k') or contains(@class, 'x1n2onr6')]")
                        
                        # Extrai informa√ß√µes
                        ad_id = re.search(r'ad_library_id=(\d+)', link.get_attribute('href'))
                        ad_id = ad_id.group(1) if ad_id else f"unknown_{idx}"
                        
                        # Texto do an√∫ncio
                        texto_completo = ad_container.text
                        
                        anuncios.append({
                            'index': idx + 1,
                            'ad_id': ad_id,
                            'url': link.get_attribute('href'),
                            'texto': texto_completo[:1000] if texto_completo else "Sem texto"
                        })
                    
                    except Exception as e:
                        continue
            
            # Estrat√©gia 2: Se n√£o encontrou com links, tenta por estrutura de card
            if len(anuncios) == 0:
                # Procura por divs que parecem ser cards de an√∫ncios
                possible_cards = self.driver.find_elements(By.CSS_SELECTOR, 
                    "div[class*='x1y1aw1k'], div[class*='x1n2onr6'], div[data-pagelet]")
                
                for idx, card in enumerate(possible_cards[:30]):
                    try:
                        texto = card.text.strip()
                        # Filtra cards que parecem ter conte√∫do de an√∫ncio
                        if texto and len(texto) > 50 and 'cookie' not in texto.lower():
                            anuncios.append({
                                'index': idx + 1,
                                'ad_id': f'card_{idx}',
                                'texto': texto[:1000]
                            })
                    except:
                        continue
        
        except Exception as e:
            st.error(f"Erro ao extrair an√∫ncios: {str(e)}")
        
        return anuncios
    
    def _scroll_progressivo(self, scrolls=5):
        """
        Scroll progressivo para carregar conte√∫do din√¢mico
        """
        for i in range(scrolls):
            try:
                # Scroll at√© o final da p√°gina
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(3)
                
                # Scroll um pouco para cima para triggar lazy loading
                self.driver.execute_script("window.scrollBy(0, -200);")
                time.sleep(1)
            except:
                break


def main():
    # Header
    st.markdown('<h1 class="main-header">üï∑Ô∏è Meta Ads Library Scraper</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">Extraia dados da Biblioteca de An√∫ncios do Facebook/Instagram</p>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("üìã Como usar")
        st.markdown("""
        **2 formas de buscar:**
        
        1Ô∏è‚É£ **Page ID**: Cole o ID num√©rico da p√°gina
        
        2Ô∏è‚É£ **URL Completa**: Cole a URL completa da biblioteca
        
        ---
        
        **‚ö†Ô∏è Importante:**
        - Primeira busca pode demorar ~15 segundos
        - Extrai at√© 30 an√∫ncios por busca
        - Funciona melhor com p√°ginas ativas
        """)
        
        st.markdown("---")
        st.markdown("**Vers√£o:** 3.0 (Refatorada)")
    
    # Inicializa driver
    driver = get_driver()
    
    if not driver:
        st.error("‚ùå N√£o foi poss√≠vel iniciar o navegador")
        st.stop()
    
    scraper = MetaAdsScraper(driver)
    
    # Tabs
    tab1, tab2 = st.tabs(["üÜî Page ID", "üîó URL Completa"])
    
    # TAB 1: Page ID
    with tab1:
        st.subheader("Buscar por Page ID")
        
        page_id = st.text_input(
            "Page ID",
            placeholder="Ex: 675929692278580",
            key="page_id_input"
        )
        
        if st.button("üîé Buscar An√∫ncios", key="btn_page_id"):
            if page_id:
                with st.spinner("üöÄ Acessando p√°gina e extraindo dados... (pode levar at√© 20 segundos)"):
                    dados = scraper.buscar_por_page_id(page_id)
                    if dados:
                        exibir_resultados(dados)
            else:
                st.warning("‚ö†Ô∏è Digite um Page ID")
    
    # TAB 2: URL Completa
    with tab2:
        st.subheader("Buscar por URL Completa")
        
        url = st.text_input(
            "URL Completa",
            placeholder="Ex: https://www.facebook.com/ads/library/?view_all_page_id=123456",
            key="url_input"
        )
        
        if st.button("üîé Buscar An√∫ncios", key="btn_url"):
            if url:
                with st.spinner("üöÄ Processando URL..."):
                    dados = scraper.buscar_por_url(url)
                    if dados:
                        exibir_resultados(dados)
            else:
                st.warning("‚ö†Ô∏è Cole uma URL")


def exibir_resultados(dados):
    """Exibe os resultados de forma clara"""
    
    if 'erro' in dados:
        st.error(f"‚ùå Erro: {dados['erro']}")
        return
    
    st.success("‚úÖ Extra√ß√£o conclu√≠da!")
    
    # M√©tricas
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üìä Total", dados.get('total_resultados', 'N/A'))
    
    with col2:
        st.metric("üì¶ Extra√≠dos", len(dados.get('anuncios', [])))
    
    with col3:
        st.metric("üïê Hora", datetime.now().strftime("%H:%M:%S"))
    
    st.markdown("---")
    
    # URL
    with st.expander("üîó URL acessada"):
        st.code(dados.get('url', 'N/A'))
    
    # An√∫ncios
    anuncios = dados.get('anuncios', [])
    
    if anuncios:
        st.subheader(f"üì¢ {len(anuncios)} An√∫ncios Encontrados")
        
        for ad in anuncios:
            with st.expander(f"An√∫ncio #{ad['index']} - ID: {ad.get('ad_id', 'N/A')}"):
                if 'url' in ad:
                    st.markdown(f"**[Ver an√∫ncio no Facebook ‚Üí]({ad['url']})**")
                st.text_area(
                    "Conte√∫do",
                    ad['texto'],
                    height=200,
                    key=f"ad_{ad['index']}"
                )
        
        # Download
        st.markdown("---")
        json_str = json.dumps(dados, ensure_ascii=False, indent=2)
        
        st.download_button(
            label="üì• Baixar todos os dados (JSON)",
            data=json_str,
            file_name=f"meta_ads_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    else:
        st.warning("‚ö†Ô∏è Nenhum an√∫ncio foi extra√≠do")
        st.info("""
        **Poss√≠veis causas:**
        - A p√°gina n√£o tem an√∫ncios ativos
        - O Page ID est√° incorreto
        - A p√°gina n√£o carregou completamente (tente novamente)
        - Estrutura do Facebook mudou (entre em contato)
        """)


if __name__ == "__main__":
    main()
